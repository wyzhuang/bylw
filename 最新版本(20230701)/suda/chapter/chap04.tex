\chapter{基于特征贡献度的样本重要性权重}
\label{chap:chap04}
这一章将在项目开发过程中预测模型迭代的场景下，基于更改级别的缺陷预测构建模型，并在模型构建的数据预处理阶段对样本施加基于特征贡献度的样本重要性权重。该方法关注易被误分类的样本，通过计算被误分类样本的特征贡献度和分类倾向性，让模型对分类倾向性与实际类别偏差较大的提交赋予较高的权重，来提高模型的预测性能。



\section{研究动机}
在上一节，我们已经讨论了项目的样本之间在时间维度上是有区别的，因此应该施加不同的权重进行训练。但是如图~\ref{chap03_project_split}所示，项目的样本数量-天数关系图并非是平滑的直线，而是呈现波峰状的，这是由于在实际的开发过程中，项目样本的提交往往呈现活跃期和沉寂期交替进行的状况。这样会使得在某一活跃期所提交的样本它们的时间权重较为相似，此时的时间权重将无法很好地区分这些样本。

为了更好地区分相近时间权重下的样本，本文将利用机器学习解释框架对同一训练批次的样本进行解释，计算它们的特征贡献度和分类倾向性，生成基于特征贡献度的样本重要性权重来对这些样本进行区分，让预测模型关注这些时间相近的样本中相对重要的部分。

此外，由于项目的时间维度贯穿整个开发周期，因此时间维度权重可以视为一种纵向权重；而特征贡献度权重是赋予相同批次的样本，因此可以视作是横向权重。显而易见的是，这两种权重是从不同方面对样本的重要性进行描述，因此，本章还讨论了这两种权重的融合对模型性能的影响。

\section{研究方法}
这一小节阐述如何利用特征贡献度来对样本的重要性进行一个评估。如图~\ref{chap04_lime_framework}所示，我们将赋予项目样本权重的过程分成两个阶段，第一是分配基础权重阶段，将样本的两种标签(模型的预测标签和人工打上的正确标签)进行比较，筛选出模型预测错误的样本，我们可以让模型重点关注这些错误的样本；第二是计算特征贡献度权重阶段，目的是为了进一步对预测错误的样本进行区分，具体来说，利用机器学习解释模型，探寻分类错误的样本为什么会出错，计算特征贡献度来判别样本的分类倾向性，根据分类倾向性的大小施加对应的权重，然后进行去噪。经过两阶段的权重赋予之后，我们用带权重的项目样本去更新预测模型。

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.9\textwidth]{../fig/chp4/lime_framework.pdf}
	\smallcaption{基于特征贡献度的样本重要性权重方法框架}
	\label{chap04_lime_framework}
\end{figure}

\subsection{分配基础权重}
我们的研究是基于预测模型迭代的场景下，即重点关注项目样本在有了模型的预测标签和人工打上的正确标签之后，即将去更新预测模型的阶段。这样在分配基础权重阶段，我们首先可以获取样本的两种标签，即模型的预测标签和人工打上的正确标签，然后将这两种标签进行比较，就能获取模型预测正确的样本和模型预测错误的样本。由于被误分类的样本可能是模型之前未学习过的，所以应该是更有价值，模型更应该关注的。因此，我们对模型预测正确的样本赋予一个较低权重$W_{l}$，对模型误分类的样本赋予一个较高权重$W_{h}$。这样可以让模型更多地关注之前误分类的项目样本，提高去预测后面项目样本的准确性。


\subsection{计算特征贡献度权重}
在分配基础权重阶段，我们给所有被预测正确的样本一个同样大小的较低权重，以及对被误分类的样本一个同样大小的较高权重，但考虑到不同样本之间仍然具有较大的差异性，赋予相同的权重并不能很好让模型针对性的关注和学习这些样本，因此，考虑到样本之间的差异，我们针对相对更重要的被预测错误的样本，再次给它们加上一个新的权重，这个权重计算步骤如下：

(1) 模型解释

首先我们通过机器学习解释模型对我们的预测模型和样本进行分析，解释样本为什么会被认为是有缺陷或者无缺陷的。如图~\ref{chap04lime_instance}所示，这是一个样本在被模型解释之后生成的特征贡献度柱状图。图中上方的“Local explanation for class 1”指的是这个柱状图表示的是样本被预测为有缺陷的情况；Y轴表示这些样本的特征值归一化后所在范围，如la $\le$ 0.08，指的是这个样本增加的代码行数在归一化后小于等于0.08，是一个很小的数值；X轴表示的特征贡献度，图中的样本特征la所赋予的贡献度为-0.13左右，即对被分类为有缺陷的贡献度是负的。这其实也符合直觉，代码增加的少，此次提交就不容易有缺陷。机器学习解释相关领域已经提出了大量的解释模型，本文采用的是被广泛运用于各领域的Lime框架~\cite{DBLP:conf/kdd/Ribeiro0G16}。

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.7\textwidth]{../fig/chp4/lime_instance.pdf}
	\smallcaption{一个样本的模型解释}
	\label{chap04lime_instance}
\end{figure}

(2) 确定特征区间和贡献度

Lime框架将特征值划分成几个区间，对每一个特征区间给一个对应的特征贡献度，因此我们需要找到这些特征空间来计算特征贡献度。由于Lime框架未给出直接显示特征区间的接口，并且对样本进行一次次解析较为耗时，因此本文采取贪婪的数据构造方法。具体来说，首先我们会对训练集和测试集都做归一化处理；然后构建一个特征值全为0的样本，即该样本的所有特征值都为0；接着用Lime框架解析该样本，获取特征值范围和贡献度；之后再构造一个样本，这个样本所有特征值刚好在上一个样本的特征值范围之外；接着再用Lime框架进行解析，获取新的特征值范围和贡献度，如此重复，直到新的构造样本所有特征值为1为止。这样我们就能得到所有特征值区间的特征贡献度。

(3) 计算分类倾向性

在确定特征区间及其对应的贡献度之后，我们可以构造出特征值和特征贡献度之间的映射函数。假设一个样本的特征值分别为$f_{1}$, $f_{2}$, $f_{3}$, ... , $f_{n}$；其中$n$为特征数量。接下来通过映射函数，我们就能获得对应的特征贡献度$c_{1}$, $c_{2}$, $c_{3}$, ... , $c_{n}$；由此我们可以得到分类倾向性$W_{c}$=$\sum_{i=1}^n c_{i}$。当$W_{c} > 0$时，说明预测模型认为该样本是具有缺陷的；当$W_{c} < 0$时，说明预测模型认为该样本是无缺陷的。

通过上述步骤，我们可以获取被缺陷预测模型误分类的样本的分类倾向性，并通过分类倾向性$W_{c}$绝对值的大小来判断预测模型将其分成某一类的意愿强度，我们引入难样本分类的思想，认为预测模型的分类意愿强度与实际类别偏差越大，说明该样本越可能是难分类样本，因此预测模型应该给予更多的关注。

(4) 去噪

一些研究指出\cite{DBLP:journals/jetai/XuJL21}，在项目的实际开发过程中，由于各式各样的原因，可能会出现测试人员打错标签的情况，这样会导致某些项目样本其实已经被预测模型正确分类了，但由于测试人员打错标签而被认为是误分类，从而影响预测模型的准确性，因此有必要对项目样本进行去噪处理。在缺陷预测领域，已经出现了较多对项目提交进行去噪的研究，本文则通过分类倾向性进行去噪。具体来说，我们将$|W_{c}| > m$的误分类样本标记为噪声，其中$m$为去噪阈值。这是因为误分类样本$|W_{c}|$过大时，说明其严重偏离了预测模型，因此有可能是被打错标签的样本。我们去除掉被标记为有噪声的样本之后，将分类倾向性权重$|W_{c}|$加到原有的高权重$W_{h}$上。由于分类倾向性权重是一个数据区间，原有的高权重是一个自定义的数值，为了防止量纲不同影响预测模型的性能，因此我们将分类倾向性权重$|W_{c}|$归约到[$W_{h}$, $2 \times W_{h}$]之间。这样最后我们得到最终的基于特征贡献度的样本重要性权重：预测模型分类正确的样本权重为$W_{l}$，预测模型分类错误的样本权重为$W_{h}+|W_{c}|$。之后，将去噪后的样本和权重输入至第三章的分类模型中进行学习和预测。



\section{实验设置}

这一节主要介绍本次实验中的实验数据集和描述、对比实验设置、性能评价指标以及参数设置等相关设置。

\subsection{实验数据集}

本章所选取的项目和第三章相同，即来自Apache和Github上的10个开源项目，项目的总时长在2至20年之间，有7个项目期限超过10年。项目总提交的数量在8845到49927之间。每个项目的都会挑选出5个活跃期，所挑选的活跃期长度在5至20个月之间。对于活跃期，本文依据时间进行划分成10个时长相等的阶段，在这10个阶段上进行缺陷预测模型的迭代，第一个阶段作为历史数据集，剩下九个阶段在每次模型迭代中依次输入训练集，即在每个任务上，预测模型迭代9次，总共有450项任务。

\subsection{对比方法}

为了能更充分地展现本文提出的方法的性能表现，这一节将选取以下方法作为对比：

(a)TRD~\cite{DBLP:conf/qrs/TianLTZ20}: 每次模型迭代数据集不会更新，仅使用项目早期数据去预测项目晚期数据的模型。

(b)Base~\cite{DBLP:journals/ijseke/ChenSW21}: 每次模型迭代使用项目的所有历史数据作为训练集，去预测新的阶段的样本是否有缺陷。

(c)TBW+gauss: 本文在第三章提出的研究方法，即在Base模型的基础上使用高斯衰减函数作为样本权重系数。

(d)CBW (Contribution-based Weights): 本章的研究方法。

(e)CBW\_without\_D (Contribution-based Weights without Denoising): 在计算特征贡献度权重阶段中没有进行去噪，其他步骤和本节研究方法保持一致。

(f)CBW\_without\_C (Contribution-based Weights without Contribution): 给分类错误的样本和分类正确的样本一个固定的权重，然后直接进行缺陷预测(即只有分配基础权重阶段的权重)。

\subsection{评价指标}

本章所选取的评价指标和第三章相同，同样使用$Acc$，$F1$和$Mcc$作为基本的评价指标。
为了排除随机因素的干扰，我们在每个任务上的实验都重复三十次，来获得更加可靠的实验结果。

\subsection{参数设置}
在本实验中，一共有四个参数，分别为低权重$W_{l}$，高权重$W_{h}$，特征贡献度权重$W_{c}$和去噪阈值$m$。其中$W_{l}$作为统一的低权重，我们将其设置为1，$W_{h}$作为统一的高权重，根据后文的参数实验结果，我们将其设置为200，$W_{c}$是通过机器模型解释框架计算得来的，无须人工确定。为了去除噪声，但又要防止过度去除了有效信息，我们参考了缺陷预测领域先前的去噪工作的研究~\cite{2020LIMCR}，$m$在实验中设置为90\%$|W_{c}|$。



\section{实验结果和分析}
在这一章节，我们将本文方法与其他方法进行对比，并对实验结果进行分析。


\subsection{与对比方法的性能比较}

在本小节中，本文将基于特征贡献度的样本重要性权重与其他方法进行比较，它们的性能如图~\ref{chap04_res_Acc}，图~\ref{chap04_res_F1}和图~\ref{chap04_res_MCC}所示。我们采取SK(Scott \& Knott)图来表现不同方法之间的性能差异。在图中，模型根据预测性能从左到右排序，性能相当的模型的框用相同的颜色表示。对于指标$Acc$，模型按照性能从优到劣进行排序，分别为CBW、TBW+gauss、Base以及TRD，平均值分别为0.778、0.772、0.769和0.733；对于指标$F1$，模型按照性能从优到劣进行排序，分别为CBW、TBW+gauss、TRD以及Base，平均值分别为0.465、0.459、0.429和0.425；对于指标$MCC$，模型按照性能从优到劣进行排序，分别为CBW、TBW+gauss、Base以及TRD，平均值分别为0.345、0.331、0.306和0.272。

从总体上来看，本文提出的CBW总是在图的最左边，并且平均值也是最高的，表明在所有指标上，CBW总是最优的，这说明了我们提出的基于特征贡献度的样本权重是有意义的。不过，从实验结果来看，基于时间维度的样本重要性权重和基于特征贡献度的样本重要性权重相差并不大，这表明了两种权重虽然从两种角度出发，但都具有相当的性能。另一个值得注意的是，从图中可以看出，CBW方法的波动程度要比TBW+gauss要大，为了探究这个现象的原因，我们分析了实验数据，发现CBW由于设置了一个高权重$W_{h}$，使得CBW方法生成的样本权重不如TBW+gauss生成的样本权重平滑，也就是说，CBW方法可能会过于关注被误分类的样本，这在大多数时候都能帮助模型更好地关注重要的样本，从而提高模型的性能；但某些时候，新产生的提交与之前被误分类的样本差异较大时，就可能会影响预测模型的性能。

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.55\textwidth]{../fig/chp4/4_res_Acc.pdf}
	\smallcaption{{基于特征贡献度的样本重要性权重与其他方法在Acc值上的性能差异}}
	\label{chap04_res_Acc}
\end{figure}

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.55\textwidth]{../fig/chp4/4_res_F1.pdf}
	\smallcaption{基于特征贡献度的样本重要性权重与其他方法在F1值上的性能差异}
	\label{chap04_res_F1}
\end{figure}

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.55\textwidth]{../fig/chp4/4_res_MCC.pdf}
	\smallcaption{基于特征贡献度的样本重要性权重与其他方法在MCC值上的性能差异}
	\label{chap04_res_MCC}
\end{figure}


\subsection{消融实验}
在本小节中，我们探讨方法的两个阶段是否具有意义，即对我们的方法进行消融实验。首先，本章提出的方法CBW作为基准对比方法，我们在CBW方法步骤中省略去噪步骤，这样产生第一个对比方法CBW\_without\_D，在CBW\_without\_D方法的基础上，我们省略了计算特征贡献度和分类倾向性来确定$W_{c}$的步骤，这样出现了第二个对比方法CBW\_without\_C。

\begin{sloppypar}
如图~\ref{chap04_ablation_all}所示，从图中可以看出，对于指标$Acc$，模型按照性能从优到劣进行排序，分别为CBW、CBW\_without\_C以及CBW\_without\_D，平均值分别为0.778、0.775和0.753；对于指标$F1$，模型按照性能从优到劣进行排序，分别为CBW、CBW\_without\_D以及CBW\_without\_C，平均值分别为0.465、0.458和0.415；对于指标$MCC$，模型按照性能从优到劣进行排序，分别为CBW、CBW\_without\_D以及CBW\_without\_C，平均值分别为0.345、0.323和0.303。
\end{sloppypar}

从总体上来看，本文提出的CBW总是在图的最左边，并且平均值也是最高的，说明了本章所提出的方法步骤是有效的。不过值得注意的是，CBW\_without\_C只保留了分配基础权重阶段的权重，然而在指标$Acc$上，CBW\_without\_C的性能却优于CBW\_without\_D。我们仔细分析了实验数据，发现CBW\_without\_D关注被误分类的样本，对它们计算特征贡献度和分类倾向性，对与真实标签差距更大的样本施加更高的权重，但由于项目提交中存在噪声，在没有去噪的情况下，可能会存在过多关注噪声的问题。此外，由于数据不平衡的原因，被误分类的样本可能大部分是有缺陷的样本，这种情况下对它们施加高权重，一方面与数据采样的方法类似，可以让模型更关注有缺陷样本，提高模型性能；另一方面也可能造成模型的过拟合，反而在一些指标上降低性能。不过总的来说，在更被广泛认可的指标$F1$和$MCC$上，CBW\_without\_D的性能都优于CBW\_without\_C，这说明了我们方法计算特征贡献度权重阶段的重要性。

\begin{figure}[!h]
	\centering
	\subfigure{
		\begin{minipage}[t]{0.45\linewidth}
			\centering
			\includegraphics[width=\textwidth]{../fig/chp4/4_ablation_Acc.pdf}
			\centerline{ \small (a) Acc上的性能表现}
			
			
		\end{minipage}
	}
	\subfigure{
		\begin{minipage}[t]{0.45\linewidth}
			\centering
			\includegraphics[width=\textwidth]{../fig/chp4/4_ablation_f1.pdf}
			\centerline{\small (b) F1上的性能表现}
		\end{minipage}
		
	}
	\subfigure{
		\begin{minipage}[t]{0.45\linewidth}
			\centering
			\includegraphics[width=\textwidth]{../fig/chp4/4_ablation_MCC.pdf}
			\centerline{\small (c) MCC上的性能表现}
		\end{minipage}
		
	}
	
	\smallcaption{消融实验的结果}
	\label{chap04_ablation_all}
\end{figure}





\subsection{参数实验和讨论}
在这一小节，我们进行参数实验和讨论，首先探讨基于时间维度的样本重要性权重与基于特征贡献度是否可以融合，以及融合之后的表现情况；然后我们对$W_{h}$这个参数做一些参数实验，寻找最为合适的参数值。

(1) 时间维度权重和特征贡献度权重是否可以融合？
基于时间维度的权重是从纵向的角度出发，贯穿项目开发的整个流程，对比较新的提交施加一个较高权重，对较旧的提交施加一个较低权重；而基于特征贡献度的权重从横向的角度出发，面对同一批次时间相近的样本，找出在上一轮模型迭代过程中被误分类的样本，并对与真实标签差距较大的样本施加更高的权重。这两种权重是从不同的角度出发，应该存在可以融合的可能，这里采取两种不同的权重融合方法，一种是$TBW\_ADD\_CBW$，对两种权重进行归一化之后得到两个权重向量，再将两个权重向量进行相加；另一种是$TBW\_MUL\_CBW$，对两种权重进行归一化之后得到两个权重向量，再将两个权重向量进行一一对应相乘。

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.74\textwidth]{../fig/chp4/4_complex_Acc.pdf}
	\smallcaption{融合权重与非融合权重在Acc值上的性能差异}
	\label{chap04_complex_Acc}
\end{figure}

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.74\textwidth]{../fig/chp4/4_complex_F1.pdf}
	\smallcaption{融合权重与非融合权重在F1值上的性能差异}
	\label{chap04_complex_F1}
\end{figure}

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.74\textwidth]{../fig/chp4/4_complex_MCC.pdf}
	\smallcaption{融合权重与非融合权重在MCC值上的性能差异}
	\label{chap04_complex_MCC}
\end{figure}



\begin{sloppypar}
如图~\ref{chap04_complex_Acc}，图~\ref{chap04_complex_F1}和图~\ref{chap04_complex_MCC}所示，为了更全面的展示两种融合方法的优劣程度，我们将这两种权重融合方法与CBW、TBW+gauss还有Base方法进行对比。从图中可以看出，对于指标$Acc$，模型按照性能从优到劣进行排序，$TBW\_ADD\_CBW$在五个方法中间排第三，$TBW\_MUL\_CBW$在五个方法中间排第五；对于指标$F1$，模型按照性能从优到劣进行排序，$TBW\_ADD\_CBW$在五个方法中间排第二，$TBW\_MUL\_CBW$在五个方法中间排第四；对于指标$MCC$，模型按照性能从优到劣进行排序，$TBW\_ADD\_CBW$在五个方法中间排第一，$TBW\_MUL\_CBW$在五个方法中间排第四。
\end{sloppypar}

从以上结果发现，两种权重融合之后的效果并不一定比单独的权重要好，尤其是对于$TBW\_MUL\_CBW$来言，甚至出现了比单独的权重都要差的情况，这是因为对于$TBW\_MUL\_CBW$来言，由于要进行权重相乘，只要样本有一个权重较小，那么总权重就会被拉低到不被关注的程度，特别是基于特征贡献度的权重给很多没被误分类的样本的权重很低，这就导致大部分样本的总权重都很低，只有非常少的两个权重值都很高的样本才会被模型关注，导致模型泛化能力降低。与$TBW\_MUL\_CBW$不同的是，$TBW\_ADD\_CBW$将两种权重相加，哪怕样本有一个权重较小，总权重也不会被拉低到不被关注的程度，因此表现较为良好，在指标$MCC$上取得了比单独权重更优秀的效果。这些实验结果表明对于权重简单粗暴地融合是行不通的，应该考虑权重的性质，寻找适合的方法来融合权重。


(2) 被误分类样本和分类正确样本之间的权重比对模型性能的影响


这一部分我们探讨$W_{h}$与的$W_{l}$之比对模型性能的影响，在本章的方法中$W_{h}$和$W_{l}$之比显然会影响模型的性能，因为当$W_{h}$和$W_{l}$之比越大时，模型就会越多关注被误分类的样本。我们把$W_{l}$的大小固定为1，所以只需要调节$W_{h}$的大小即可。

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.7\textwidth]{../fig/chp4/4_para_prop.pdf}
	\smallcaption{不同权重比下模型性能的大小}
	\label{chap04_para_prop}
\end{figure}

如图~\ref{chap04_para_prop}所示，我们设置$W_{h}$大小分别为1、2、5、10、20、50、100、200和500。当$W_{h}$为1时，代表将被误分类样本和被正确分类样本同等看待。结果表明，随着$W_{h}$的值逐渐增大，模型在指标$F1$和$MCC$的性能也逐渐提高，但在指标$Acc$上的性能反而逐渐下降。我们对实验数据进行了分析，发现当$W_{h}$的值增大时，模型对误分类样本提供了更多的关注，由于误分类样本其中很多是有缺陷的样本，这样模型会加大对缺陷样本的关注，从而有效提高在指标$F1$和$MCC$上的表现；同时，由于被误分类样本占样本总数不多，当模型对这些样本施加更多关注时，也可能会有些忽视大多数被正确分类的样本，导致在指标$Acc$上的表现有所下降。不过总体来言，随着$W_{h}$值的逐渐增大，缺陷预测模型的性能表现会越来越好。我们综合三个指标，最后确定$W_{h}$的值为200。


(3) 本章方法的时间开销



表\ref{chap04_tab_time_cost}展示了本章方法的时间开销，并与第三章的方法进行对比。从表中可以看出，本章方法的时间开销是毫秒级的，这意味着本章方法的时间开销是可以接受的。不过与时间权重不同的是，时间权重的时间开销与项目的时长以及样本数量紧密相关；而特征贡献度权重的时间开销却更加稳定。这是因为基于特征贡献度的权重计算花费主要来源于机器学习解释模型对样本特征进行解释的时间，由于本章采取贪婪的方法，每次任务只需要构造几个特殊样本即可获取特征区间至特征贡献度的映射函数，从而有效降低了时间开销。虽然与时间权重相比，基于特征贡献度的权重时间开销较大，但是仍然远低于很多机器学习模型学习的时间花费，因此本章方法所提出的权重同样不会造成很多额外的测试资源花费。
\begin{table}[width=.9\textwidth,pos=htbp]
	\smallcaption{两种权重时间开销对比}
	\label{chap04_tab_time_cost}
	\centering
	
	\begin{tabular}{ccc}
		\hline
		项目  &TWB+gauss(毫秒) &CWB(毫秒) \\\hline
		ambari     &0.94     &5.84   \\
		ant        &0.53     &5.31   \\
		aptoide    &0.44     &5.43   \\
		camel      &0.93     &5.62   \\
		cassandra  &0.82     &5.49   \\
		egeria     &0.67     &5.80   \\
		felix      &0.60     &5.60   \\
		jackrabbit &0.34     &5.62   \\
		jenkins    &1.10     &5.67   \\
		lucene     &1.22     &5.99   \\
		
		\hline
	\end{tabular}
\end{table}



\section{本章小结}
本章在即时软件缺陷预测领域，针对时间相近的样本以及在模型上一轮迭代中被误分类的样本，提出了一种基于特征贡献度的样本重要性权重。本章在10个项目，每个项目5个数据区间上，9次模型迭代上进行实证研究，通过三种评价指标评估模型性能，将本文的方法与其他方法进行比较，并进行了消融实验，最终的实验结果表明了本文所提出的基于特征贡献度的样本重要性权重的有效性。我们还探究了基于时间维度的样本重要性权重和基于特征贡献度的样本重要性权重的融合，结果表明需要寻找合适的方法进行融合才能保证预测模型的性能。最后，我们进行参数实验，讨论被误分类样本权重与被正确分类样本权重之比对模型性能的影响。结果表明，在一定范围内，对被误分类样本关注越多，模型性能越好。

