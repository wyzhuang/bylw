\chapter{基于样本重要性权重的数据采样方法}
\label{chap:chap04}
这一章将在项目开发过程中预测模型迭代的场景下，基于更改级别的缺陷预测构建模型，并针对类不平衡问题，在模型构建的数据预处理阶段对数据进行采样处理。该方法通过两种样本重要性权重，对样本重要程度进行排序并挑选部分最重要的样本作为中心样本；并将权重矩阵和特征矩阵进行拼接之后来寻找近邻样本，这样使得用于合成新样本的样本都是重要样本，从而提高即时软件缺陷预测的性能。


\section{研究动机}
在即时软件缺陷预测领域，软件更改数据通常是类不平衡的，在大部分项目上，会引入缺陷的变更数量往往远少于不含有缺陷的变更数量~\cite{DBLP:journals/tse/SongGS19}。如果不对不平衡的数据进行处理，会导致大多数机器学习算法只关注多数类(无缺陷样本)中的特征，而忽视了学习少数类(有缺陷样本)中的特征。

为了解决即时软件缺陷预测中的类不平衡问题，数据采样技术被广泛采用，用于在数据预处理阶段平衡训练集数据的分布，以提高预测模型的性能。在缺陷预测领域，一般认为过采样比欠采样更可取，因为在欠采样过程中丢弃的样本可能包含预测模型的有用和重要信息。在过采样中，基于少数样本合成新样本的方法最为流行，比如SMOTE方法。SMOTE方法通过挑选某个样本，寻找它的近邻样本来合成新的样本。然而它的问题有三个：一是随机挑选中心样本，导致挑选的中心样本不具有代表性，不能很好地反映数据集的特征；二是中心样本只与空间距离最近样本结合，生成的数据不具有多样性，容易让模型陷入过拟合；三是对所有特征维度同等看待，不能反映不同特征的重要程度。

针对上述问题，本章结合第三章和第四章提出的两种样本重要性权重，来挑选部分重要样本作为中心样本，以改进随机挑选的问题；合并特征矩阵和权重矩阵，来计算近邻样本，以改进生成数据不多样的问题；权重有一部分是通过计算特征贡献度得到的，以改进对所有特征同等看待的问题。
\section{研究方法}
这一节阐述如何利用两种样本重要性权重对数据不平衡问题进行处理。如图~\ref{chap05_framework}所示，首先我们从不平衡数据集中提取少数类，并获取这些少数类样本的权重系数；接着将样本特征矩阵和权重系数矩阵合并，并根据权重进行排序，挑选最重要的部分样本作为中心样本；然后我们对中心样本进行遍历，并根据合并后的加权特征矩阵来计算近邻样本，最后合成新的少数类样本，使数据集平衡。值得注意的是，由于我们在计算基于特征贡献度的样本重要性权重的时候，会对样本进行去噪处理，因此我们的方法并不是完全的过采样方法，可以视为一种混合采样方法。
\begin{figure}[!h]
	\centering
	\includegraphics[width=1\textwidth]{../fig/chp5/5_framework.pdf}
	\smallcaption{基于样本重要性权重的数据采样方法框架}
	\label{chap05_framework}
\end{figure}

\subsection{计算权重系数}
根据第三章和第四章，我们可以为已经打上真实标签的样本计算两种样本重要性权重。这样，我们在从不平衡的数据集中提取少数类样本之后，也能得到少数类样本的两种权重。对于两种权重，首先为了保证量纲一致，我们对所有的特征向量和权重都进行归一化处理，接着，根据第四章关于两种特征融合的讨论结果，我们取两种权重的平均值作为这些少数类样本的权重系数。这样，对于每一个少数类样本，我们都可以得到它的特征向量 [$f_{1}$, $f_{2}$, $f_{3}$, ... , $f_{n}$] 以及一个权重系数$w$。

\subsection{挑选中心样本}



在得到少数类的特征向量和权重系数之后，我们将用它们来挑选中心样本。首先，根据特征向量的维度，我们对权重系数进行重复扩增，得到一个维度和特征向量相同的权重向量，并将特征向量和权重向量进行拼接，生成一个扩增特征向量。这样，对于每一个少数类样本，我们都可以得到它的扩增特征向量[$f_{1}$, $f_{2}$, $f_{3}$, ... , $f_{n}$, $w_{1}$, $w_{2}$, $w_{3}$, ... , $w_{n}$]。

得到扩增特征向量之后，我们按照权重系数$w$的大小对样本进行排序，这样排在前面的就是相对比较重要的样本。排序之后，我们选取前$\alpha$\%个样本作为中心样本，$\alpha$是一个可调节的参数，根据后文的参数实验，本文将$\alpha$设置为50。由于这些中心样本是根据基于时间维度的样本权重和基于特征贡献度的样本权重平均排名得到的，所以这些样本要么是时间较新，更能代表当前项目提交特征的；要么如图~\ref{chap05_imbalance_weight}所示，是靠近类的边缘，容易被误分类的样本。我们认为这些比较重要的样本作为中心样本时，将比随机挑选的中心样本更具有代表性，更能提高预测模型的性能。

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.65\textwidth]{../fig/chp5/5_imbalance_weight.pdf}
	\smallcaption{根据权重挑选重要有缺陷样本的示意图}
	\label{chap05_imbalance_weight}
\end{figure}
\subsection{合成少数样本}
在挑选出中心样本之后，我们就可以根据中心样本来寻找近邻样本，并合成新的少数类样本。对于中心样本的集合，我们对其按权重由大到小进行遍历，对于每个中心样本，我们按照扩增的特征向量来计算近邻样本，这样做的好处在于可以拉近重要程度相近的样本之间的距离，与比只按照特征向量来计算近邻样本的方法相比，会有两方面的好处：一方面可以让两个比较重要的样本有更大的概率结合，合成的新样本更具有代表性；另一方面重要程度相近的样本不一定空间距离相近，这样合成的新样本更多样。

计算完所有中心样本的近邻样本之后，对于一个中心样本$C_{i}$，可以得到一个近邻样本序列[$N_{i1}$, $N_{i2}$, $N_{i3}$, ... , $N_{im}$]，在序列中近邻样本按照离中心样本的距离从近到远进行排列。值得注意的是，序列长度$m$的大小为少数类样本的长度减一，即所有少数类样本都在中心样本选择近邻样本的范围之内，这样做的目的同样是为了增强合成新样本的多样性。这样在第一轮遍历中，对于中心样本$C_{i}$，它将与$N_{i1}$进行结合产生新样本；如果第一轮遍历结束，新生成的样本数量仍然不足以让少数类样本扩增到与多数类样本相同大小，我们将进行下一轮遍历，这样$C_{i}$将与$N_{i2}$相结合，以此类推，直到能让数据集平衡为止。在遍历过程中，往往会出现一个样本既作为中心样本，又作为某个样本的近邻样本，可能导致重复合成相同的样本，对于这种情况我们会记录合成历史，不重复合成相同样本。

当然，可能会存在一种极端情况，即在数据集严重不平衡的情况下，经过$m$次遍历，中心样本与其他所有样本都合成一遍之后，数据集仍然不平衡。对于这种情况，我们将把合成的新样本与原来的少数类样本进行合并，生成新的少数类样本集合，之后我们在新的少数类样本集合上重复执行本章的基于样本权重的数据采样方法，直到能让数据集平衡为止。

具体的合成方法与SMOTE中的合成方法一致，即在中心样本与近邻样本之间随机产生一个新的样本。



\subsection{平衡数据集}
在生成足够多的少数样本之后，由于现在少数类样本的特征向量都是包含权重系数的扩增特征向量，因此，我们需要对样本去除权重系数矩阵，只保留特征矩阵，然后与原来的多数类样本组成一个平衡的数据集。值得注意的是，与前两章方法不同，为了保证后续实验的公平性，所有样本将不会给它们施加任何权重。



\section{实验设置}
这一节主要介绍本次实验中的实验数据集和描述、对比实验设置以及性能评价指标等相关设置。

\subsection{实验数据集}

本章所选取的项目和第三章相同，即来自Apache和Github上的10个开源项目，项目的总时长在2至20年之间，有7个项目期限超过10年。项目总提交的数量在8845到49927之间。每个项目的都会挑选出5个活跃期，所挑选的活跃期长度在5至20个月之间。对于活跃期，本文依据时间进行划分成10个时长相等的阶段，在这10个阶段上进行缺陷预测模型的迭代，第一个阶段作为历史数据集，剩下九个阶段在每次模型迭代中依次输入训练集，即在每个任务上，预测模型迭代9次，总共有450项任务。

\subsection{对比方法}

为了能更充分地展现本文提出的方法的性能表现，这一节将选取以下方法作为对比：

(1) 未使用数据采样技术的基础模型

(1-a)Base~\cite{DBLP:journals/ijseke/ChenSW21}: 使用项目的所有历史数据作为训练集，去预测新的阶段的样本是否有缺陷。

(2) 过采样方法

(2-a)ROS (Random Oversampling)~\cite{DBLP:conf/icml/HulseKN07}: 使用随机过采样算法来中进行类再平衡。

(2-b)SMOTE~\cite{DBLP:journals/jair/ChawlaBHK02}: 使用SMOTE算法来进行类再平衡。

(2-c)ORB (Oversampling Rate Boosting)~\cite{DBLP:conf/icse/CabralMSM19}:一种过采样方法，使用Boosting方法动态地调节每次迭代过程中的过采样率。

(3) 欠采样方法

(3-a)RUS (Random Undersampling)~\cite{DBLP:conf/icml/HulseKN07}: 使用随机欠采样算法来进行类再平衡。

(3-b)Filtering~\cite{DBLP:journals/tse/TabassumMF23}: 一种欠采样方法，计算欧式距离来保留与最新项目提交较接近的项目历史数据。

(4) 本文提出的方法

(4-a)WBO (Weight-based Oversampling): 本节的研究方法。

(4-b)WBO\_without\_T : 去掉时间权重，仅使用特征贡献度权重，其他步骤与本节研究方法保持一致。

(4-c)WBO\_without\_C: 去掉特征贡献度权重，仅使用时间权重，其他步骤与本节研究方法保持一致。

\subsection{评价指标}

本章所选取的评价指标和第三章相同，同样使用$Acc$，$F1$和$Mcc$作为基本的评价指标。
为了排除随机因素的干扰，我们在每个任务上的实验都重复三十次，来获得更加可靠的实验结果。



\section{实验结果和分析}
在这一章节，我们将本文方法与其他方法进行对比，并对实验结果进行分析。


\subsection{与对比方法的性能比较}


在本小节中，本文将基于样本重要性权重的数据采样方法与其他方法进行比较，它们的性能如图~\ref{chap05_res_Acc}，图~\ref{chap05_res_F1}和图~\ref{chap05_res_MCC}所示。我们采取SK(Scott \& Knott)图来表现不同方法之间的性能差异。在图中，模型根据预测性能从左到右排序，性能相当的模型的框用相同的颜色表示。对于指标$Acc$，模型按照性能从优到劣进行排序，分别为Base、WBO、SMOTE、ORB、ROS、RUS以及Filtering，平均值分别为0.769、0.703、0.702、0.701、0.701、0.689和0.673；对于指标$F1$，模型按照性能从优到劣进行排序，分别为WBO、ORB、ROS、SMOTE、Filtering、RUS以及Base，平均值分别为0.534、0.523、0.522、0.520、0.512、0.499和0.425；对于指标$MCC$，模型按照性能从优到劣进行排序，分别为WBO、ORB、ROS、Filtering、SMOTE、RUS以及Base，平均值分别为0.349、0.342、0.331、0.329、0.328、0.327和0.306。

从总体上来看，本文所提的方法WBO在两个指标上排第一，一个指标上排第二，说明了WBO方法的有效性。对于指标$Acc$，没有用不平衡技术进行处理的Base方法效果最好，这是因为在对于不平衡的数据集，模型会倾向于将结果预测为多数类，这样就能得到虚高的$Acc$性能，但是从另两个指标$F1$和$MCC$上看，Base方法的效果总是最差的，这也说明了对于不平衡数据集，应该综合多种指标，尤其是能全面反映模型性能的指标。

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.7\textwidth]{../fig/chp5/5_res_Acc.pdf}
	\smallcaption{基于样本重要性权重的过采样方法与其他过采样方法在Acc值上的性能差异}
	\label{chap05_res_Acc}
\end{figure}

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.7\textwidth]{../fig/chp5/5_res_F1.pdf}
	\smallcaption{基于样本重要性权重的过采样方法与其他过采样方法在F1值上的性能差异}
	\label{chap05_res_F1}
\end{figure}

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.7\textwidth]{../fig/chp5/5_res_MCC.pdf}
	\smallcaption{基于样本重要性权重的过采样方法与其他过采样方法在MCC值上的性能差异}
	\label{chap05_res_MCC}
\end{figure}

将过采样方法与欠采样方法进行对比，我们发现，两种欠采样方法RUS和Filtering，在三个性能指标上的大部分情况下都劣于SMOTE、ORB和ROS这三种过采样方法。这些结果表明在即时软件缺陷预测中，欠采样方法的性能表现不如过采样方法，这是因为欠采样方法在丢弃多数类样本的同时，也会丢失许多有重要信息的数据，因此，我们认为，在即时软件缺陷预测领域，为了获得更好的预测性能，我们应该采用过采样方法来对数据集进行平衡。

另一个值得注意的现象是，在指标$F1$和$MCC$上，SMOTE方法的性能表现不如ROS，这个结果与以前的研究报告的不太一样。我们分析了实验数据，发现正如相关研究\cite{DBLP:conf/icic/HanWM05}指出的那样，SMOTE方法从处于类边界的少数类样本中合成新样本时，其近邻样本也是在边界，这样合成的新样本也会落在类的边界，使得边界变得更加模糊，从而导致预测性能受到负面影响。而本文提出的方法WBO通过扩增特征向量来计算近邻样本，拉近了重要样本彼此之间的距离，使得生成的新样本不一定落在类边界，在一定程度上改善了这个问题。


\subsection{消融实验}


在本小节，我们对本章所提出的基于样本重要性权重的数据采样方法进行消融实验，设置了两个对比方法WBO\_without\_T和WBO\_without\_C，分别为只用基于特征贡献度的权重和只用时间维度的权重，其他地方与本文提出的方法WBO保持一致。

\begin{sloppypar}
如图~\ref{chap05_ablation_all}所示，从图中可以看出，对于指标$Acc$，模型按照性能从优到劣进行排序，分别为WBO、WBO\_without\_C和WBO\_without\_T，平均值分别为0.703、0.699和0.694；对于指标$F1$，模型按照性能从优到劣进行排序，分别为WBO、WBO\_without\_T和
WBO\_without\_C，平均值分别为0.547、0.535和0.535；对于指标$MCC$，模型按照性能从优到劣进行排序，分别为WBO、WBO\_without\_C和 WBO\_without\_T，平均值分别为0.349、0.342和0.341。
\end{sloppypar}


从总体上来看，本文提出的WBO总是在图的最左边，并且平均值也是最高的，说明了本章所提出的方法中两种权重融合的步骤是有效的，不过从图中也可以看出，三种模型的性能其实是相当的，这与第四章的讨论结果类似，当我们对权重进行平均来作为混合权重时，只能得到很小的改善。不过与第四章的讨论有所区别的是，由于实验方法和实验场景的不同，实验结果也有所差异。

从实验方法来看，第四章的权重混合是在模型训练的时候根据两种权重来关注更加重要的样本，这样每个样本的重要程度具有绝对的顺序；而本章方法是根据权重大小将少数类样本划分成重要样本和非重要样本，并以重要样本为中心样本来合成新样本，这样本章的样本重要程度并没有绝对的顺序，不同权重的参与使得中心样本的选择更加全面，生成样本更具有代表性和多样性。


\begin{figure}[!h]
	\centering
	\subfigure{
		\begin{minipage}[t]{0.45\linewidth}
			\centering
			\includegraphics[width=\textwidth]{../fig/chp5/5_ablation_Acc.pdf}
			\centerline{ \small (a) Acc上的性能比较}
			
			
		\end{minipage}
	}
	\subfigure{
		\begin{minipage}[t]{0.45\linewidth}
			\centering
			\includegraphics[width=\textwidth]{../fig/chp5/5_ablation_f1.pdf}
			\centerline{\small (b) F1上的性能比较}
		\end{minipage}
		
	}
	\subfigure{
		\begin{minipage}[t]{0.45\linewidth}
			\centering
			\includegraphics[width=\textwidth]{../fig/chp5/5_ablation_MCC.pdf}
			\centerline{\small (c) MCC上的性能比较}
		\end{minipage}
		
	}
	
	\smallcaption{两种权重的过采样方法与单个权重方法的性能比较}
	\label{chap05_ablation_all}
\end{figure}

从实验场景来看，第四章实验时由于只探讨权重的不同对预测模型性能的影响，为了实验的公平性，我们对数据集不做任何修改，因此某个样本被标记为噪声，只是将权重设为0，而不是直接剔除。这样在权重混合时，这些噪声样本可能会有另一个权重而仍然受到模型的关注，从而降低预测模型性能。与之不同的是，第五章的各种数据采样方法本来就会对数据集进行修改，因此此时被标记为噪声的样本就会从数据集中剔除，不会被用来合成新的样本，所以数据集的可靠性得到增强，从而提高预测模型的性能。

\subsection{参数实验和讨论}

(1) 少数样本采样范围对模型性能的影响


这一部分我们探讨对少数样本设置的采样范围$\alpha$\%的大小对模型性能的影响。采样范围$\alpha$\%的不同，会使得用来作为中心样本的少数样本发生变化，同时影响遍历次数，使得合成的新样本也有所不同，因此我们认为参数$\alpha$会对预测模型的性能产生影响。

如图~\ref{chap05_para_prop}所示，我们设置参数$\alpha$值分别为10、20、30、40、50、60、70、80、90以及100。值得注意的是，哪怕参数$\alpha$值等于100，我们的方法与SMOTE方法也有极大的区别，首先是我们在计算近邻样本时，采用的是扩增特征向量进行计算的；其次，我们是采用权重从高到低依次遍历的方式来合成新样本，而不是随机挑选。

从实验结果上来看，我们提出的基于样本重要性权重的数据采样方法的性能随着$\alpha$的增大先变大后减少，在$\alpha$等于50的时候，综合所有指标取得最大值，因此在本章方法的参数$\alpha$设置为50。这是因为当采样范围过低时，中心样本不得不与距离较远的样本相结合，而两个距离较远的样本结合时，可能会导致合成的新样本落入到多数类的范围里，从而对预测模型的性能产生负面影响\cite{DBLP:journals/infsof/FengKYXBKZ21}；当采样范围过大时，会使得不重要的样本结合生成新的样本，这种新生成的样本同样也很难对模型起到正面影响。除此之外，观察三条曲线，我们可以发现指标$Acc$的曲线趋势往往与$F1$和$MCC$相反，这与之前的实验结果保持一致，这似乎说明，当我们想要在类平衡的指标上取得更优秀的成绩时，往往不得不牺牲$Acc$指标。最后，我们还能看出，参数实验几个指标的波动不是非常剧烈，说明我们的方法其实是参数不敏感的，这是因为我们没有采用随机选择的方式，而是固定地从高权重的样本开始合成新的样本，这在一定程度上保持了方法的稳定性。

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.7\textwidth]{../fig/chp5/5_para_prop.pdf}
	\smallcaption{少数样本不同采样范围下模型性能的变化情况}
	\label{chap05_para_prop}
\end{figure}

(2) 任务数据的不平衡率对模型性能的影响

这一部分我们探讨任务数据的不平衡率对模型性能的影响。按照理想情况，数据集的不平衡率越高，原本不平衡的预测模型对多数类关注越高，使得实际性能下降越多，这样当采用不平衡技术时，模型所能获得的改善越高，因此我们设计了实验，探究WBO方法在不同缺陷率任务下的对预测模型的性能改善。由于$MCC$指标对$TP$，$TN$，$FP$和$FN$都进行了综合考量，更能全面反映预测模型在不平衡数据集上的性能表现，因此这一部分我们以$MCC$作为评价模型性能的指标。

如图~\ref{chap05_rate_MCC}所示，这个散点图展示了WBO方法在450个任务上对即时软件缺陷预测模型的性能改善情况，其中横坐标为某次任务的数据集中有缺陷样本占总样本的比率，当横坐标小于0.5时，说明在不平衡数据集中有缺陷的样本为少数类；当横坐标等于0.5时，说明这次任务的数据集是平衡的；当横坐标大于0.5时，说明在不平衡数据集中有缺陷的样本为多数类。纵坐标为预测模型采用WBO方法对数据进行平衡和预测模型没有采用任何不平衡方法之间的性能差值，当纵坐标大于0时，说明WBO方法在这个任务上有效提高了预测模型的性能；当纵坐标等于0时，说明WBO方法在这个任务上对预测模型没有任何影响；当纵坐标小于0时，说明WBO方法在这个任务上反而对预测模型有负面影响。为了更清晰地展现WBO方法在450个任务上的性能表现，我们在图中绘制了$y=0$的红色虚线。

从图中的横坐标来看，在绝大多数任务的数据集，有缺陷样本是少数类，只有极少部分任务上有缺陷样本是多数类。所有任务数据集缺陷率的中位数是0.254，即有接近一半的任务数据集中，有缺陷样本在总样本的比例不到四分之一，这说明我们实验所用的任务数据集存在比较明显的类不平衡问题。

从图中的纵坐标来看，在大部分任务上，应用WBO方法前后，预测模型的$MCC$差值都大于0，这说明了本文提出的WBO方法的有效性。结合横坐标的缺陷率来看，我们发现，当缺陷率在小于0.4的情况下，在$y=0$虚线上方的实验结果远远多于在$y=0$虚线下方；但是当缺陷率在0.5附近的时候，在$y=0$虚线上方的实验结果反而少于在$y=0$虚线下方，这说明WBO方法更加适合不平衡程度较高的数据集，并且从总体上来说，数据集的不平衡程度越高，WBO方法所能改善的效果越好。

虽然从整体的实验结果来说，WBO方法对不平衡数据集上的预测模型有着明显的改善效果，但是仍然在部分任务上表现不佳。我们对数据集和实验过程进行了详细分析，发现问题主要出现在数据集上，数据集的一些内在数据集特征，即小析取、缺乏密度、缺乏类可分性、噪声数据和数据集偏移等问题对类不平衡技术的影响较大，对于一些上述问题较多的数据集，在进行平衡处理之后，效果不但没有提升，反而有所下降。这种现象不是我们的WBO方法独有的，相关实证研究~\cite{DBLP:journals/tse/SongGS19}报告了常见的类不平衡技术也会出现类似的问题。

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.7\textwidth]{../fig/chp5/5_rate_MCC.pdf}
	\smallcaption{不同缺陷率下应用WBO数据采样方法前后模型的性能差异}
	\label{chap05_rate_MCC}
\end{figure}


\section{本章小结}
本章在即时软件缺陷预测领域，基于两种样本重要性权重，提出了一种数据采样方法，用于解决数据集类不平衡的问题。本章在10个项目，每个项目5个数据区间上，9次模型迭代上进行实证研究，通过三种评价指标评估模型性能，将本文的方法与其他方法进行比较，并进行了消融实验，最终的实验结果表明了本文所提出的基于样本重要性权重的数据采样方法的有效性。我们还进行参数实验，探讨对少数样本设置的采样范围$\alpha$\%的大小对模型性能的影响，结果表明$\alpha$值过大和过低可能会被模型的性能产生负面影响。最后我们还讨论了任务数据的不平衡率对模型性能的影响，实验结果表明，从总体上来说，数据集的不平衡程度越高，本文所提出的WBO方法所能改善的效果越好。

