\chapter{背景知识}
\label{chap:chap02}


本章将对本论文涉及到的背景知识分三个部分进行简要介绍。首先介绍即时软件缺陷预测的基本流程，其次将介绍即时软件缺陷预测中的所必需的软件特征，最后将介绍类不平衡技术的相关概念。

\section{即时软件缺陷预测基本流程}
现代软件开发是协作和敏捷的，具有持续交付和持续部署等流行趋势，旨在以更高的速度和频率构建、修复和发布软件。由于这一增长趋势，近年来在缺陷预测的一个新的子领域，即时软件缺陷预测的相关研究越来越多\cite{cl2019}，该领域旨在预测每次软件更改的缺陷可能性。

图~\ref{chap02_jit_framework}展示了整个即时软件缺陷预测工作流程的概述。开发人员通常使用源代码管理系统或版本控制系统，来记录每次提交产生的软件更改，并通过缺陷追踪系统记录每次提交是否具有缺陷。接下来，数据采集步骤是将提交信息转换为原始变更数据(例如，从变更集计算软件变更度量)以及记录提交是否具有缺陷。从原始变更数据中，我们准备好用于构建模型的特征矩阵，通常将此步骤称为数据预处理。最后就是构建预测模型来识别新产生的提交是否有缺陷。
\begin{figure}[!h]
	\centering
	\includegraphics[width=0.9\textwidth]{../fig/chp2/2_jit_framework.pdf}
	\smallcaption{即时软件缺陷预测的基本流程框架}
	\label{chap02_jit_framework}
\end{figure}

\subsection{数据采集}
数据采集包括特征提取和数据标注，特征提取指将代码变更信息提取为原始特征数据，数据标注指将软件变更标注为缺陷引入变更和非缺陷引入变更。特征提取将在第2.2节具体阐述，这一节主要阐述数据标注相关背景知识。

在即时软件缺陷预测领域，数据标注是非常具有挑战的一个研究领域，因为首先软件变更本来就是不直观，难以确定的\cite{DBLP:journals/ese/NugrohoHM20,DBLP:conf/icse/RosaPSTBLO21}。软件变更是版本控制系统中软件的两个修订版之间的差异，在完成对软件项目的修改后，开发人员使用提交命令将更改记录到版本控制系统中，从而在版本控制系统中创建新的修订号。我们将软件更改计算为版本控制系统中两个连续修订的差异。讨论提取影响数据质量的软件更改数据集非常复杂，有各种不同的diff算法来计算两个文件之间的差异。表~\ref{chap02_tab_diff}中列出了目前缺陷预测领域比较流行的四种diff算法。

\begin{table}[width=.9\textwidth,pos=htbp]
\smallcaption{四种软件变更的diff算法}
\label{chap02_tab_diff}
\centering

\begin{tabular}{cc}
	\hline
	算法名称 & 描述\\\hline
	Myers & 从同一文件的两个版本的第一行开始依次扫描代码行，以找到彼此匹配的行对\\
	Minimal & 通过比较两个Myers对象，使得补丁大小尽可能小\\
	Patience & 注意标记行的最长公共子序列，关注出现次数最少但至关重要的行\\
	Histogram & 构建直方图，对代码行有序匹配，统计元素存在次数\\
	
	\hline
\end{tabular}
\end{table}

其次，测试并没有向我们揭示哪种软件更改会在模块中引入导致测试失败的缺陷，那我们如何为软件更改分配缺陷标签或干净标签？为了解决这个问题，Sliwerski等人~\cite{DBLP:journals/sigsoft/SliwerskiZZ05}提出了一种基于缺陷修复变化自动识别缺陷诱导变化的算法，该算法现在被称为SZZ，以三位发明人的首字母缩写命名。SZZ 算法的一般框架包含了以下几个步骤：首先，检查版本控制系统中的提交日志消息或发布报告，通过在文本中搜索自然语言模式或者寻找发布报告的相关信息等方式来识别缺陷修复更改；其次，对于这些缺陷修复更改代码，通过diff算法，定位到这些缺陷的代码行；然后在更改历史中向后搜索，以找到引入缺陷的更改集；最后，进行去噪处理，丢弃提交时间晚于缺陷报告时间的代码变更。



\subsection{数据预处理}
用于构建即时软件缺陷预测模型的输入数据通常是一个向量，由特定变更集的特征值组成。这些向量是数据采集步骤的结果，多个变更集的向量集合形成一个矩阵。在大多数情况下，矩阵数据（例如变更集的软件度量）在构建即时软件缺陷预测模型之前需要额外的转换。基于这样的矩阵，我们将转换技术分为两类：基于行和基于列。

基于行的方法主要是数据采样方法，分为过采样技术和欠采样技术。过采样技术通过增加多数类样本来平衡数据集，比如随机过采样方法。欠采样技术通过减少多数类样本来平衡数据集，比如随机欠采样方法。在缺陷预测领域中，欠采样不如过采样常见，因为从多数类中删除的样本可能包含可供分类器学习的重要信息。

基于列的方法主要关注特征倾斜，特征共线的问题~\cite{DBLP:journals/tr/DuanXFY22,DBLP:journals/tse/FanXCLHL21}。特征倾斜指软件变更数据的大多数特征都是高度偏斜的(例如，一些变量在0和1之间变化，而其他变量则高出几个数量级 )，许多特征不是正态分布的。大多数统计和机器学习算法都期望自变量的值是标准化的，例如，流行的机器学习库，处理这一标准化问题的最流行方法是对软件度量应用对数变换。特征共线是指两个特征或者一个特征与其他多个特征相互关联。这会带来两方面的问题，一方面由于特征的共线，逻辑回归模型可能出现数值非唯一性，其中数值非唯一是指无法确定一组唯一的模型参数；另一方面相关特征也可能导致对单个特征在预测缺陷引起的软件变化方面的影响的误解。主要解决方法是使用相关性分析、独立性分析和冗余分析的组合消除相关或多重相关的变量。


\subsection{模型构建}
在即时软件缺陷预测领域，大多数模型是机器学习模型，关于缺陷模型的研究非常丰富，在下面做些陈述。

按数据是否有标签，可分为有监督模型和无监督模型。传统的有监督即时软件缺陷预测模型通常需要训练数据带有正确的标签，利用机器学习分类器比如逻辑回归、朴素贝叶斯、支持向量机、决策树和神经网络等对数据进行学习和分类，不过会存在由于数据标注较为困难，使得传到预测模型的数据往往存在噪声的问题。无监督即时软件缺陷预测是指利用未知标签变更数据构建预测模型的技术。最简单的无监督即时预测模型就是按代码行来分类，可以将代码变更较多的提交预测为有缺陷的，或者将代码变更较少的提交预测为无缺陷的。目前即时软件缺陷预测领域的无监督模型大多不复杂，但是在一些指标上许多简单的无监督模型比最先进的有监督模型表现得更好。不过，一般来言，无监督模型并不比有监督模型更有竞争力。

按关注的任务不同，分为非工作量感知模型和工作量感知模型。非工作量感知模型将所有的提交同等看待，对于预测结果和模型性能的衡量，通常采取机器学习领域常用的性能指标,包括机器学习领域常用的精确度(precision)、召回率(recall)、$F1$和正确率(accuracy)等。
工作量感知模型关注项目提交的实际复杂程度，观察到较小的模块在比例上更容易出现缺陷，应该首先进行检查，评估模型性能时通常采取即时软件缺陷预测领域研究者提出的工作量感知指标，比如关注检查前20\%的代码行所能找到的缺陷比例的$PofB20$、软件测试人员在首次成功检查到缺陷之前所需要检查模块数的$IFA$等。

按实验的场景不同，分为项目内缺陷预测和跨项目缺陷预测。项目内缺陷预测是根据一个项目的历史软件更改和缺陷数据来训练预测模型，并使用该模型对同一项目进行缺陷预测或工作量感知预测。跨项目缺陷预测\cite{cs2020}是根据一个或多个源项目的变化和缺陷数据建立预测模型，并使用该模型来预测目标项目的提交是否具有缺陷。由于不同项目数据往往差异很大，存在特征漂移等问题，因此跨项目缺陷预测的难度往往大于项目内缺陷预测。



\section{软件特征}

软件特征用来描述软件模块，帮助预测模型区分软件模块是否具有缺陷。在即时软件缺陷预测领域，研究者们提出了多种特征\cite{myq2023}，包括基于变更元数据的特征、基于变更代码内容的特征、基于软件演进过程的特征和基于多源软件制品的特征。本节对这4种特征分别进行概述。

\subsection{基于变更元数据的特征}

变更元数据是指描述变更属性(例如开发者、提交时间、变更日志、修改文件、每个文件增加和减少的代码行数等)的数据，通常来说，缺陷预测研究者可以从项目的历史提交记录中直接获取这些变更元数据。表~\ref{chap02_tab_meta}中列出一些常用的基于变更元数据的特征。在变更元数据基础之上，Mockus等人~\cite{DBLP:journals/bell/MockusW00}提出了变更增加减少行数、修改文件数量、开发者经验、变更类型等特征。由于这些特征显而易见，容易被理解和计算，具有普遍性，能够较好地反映项目的变更情况，因此被应用到大量的即时软件缺陷预测研究中。

\begin{table}[width=.9\textwidth,pos=htbp]
	\smallcaption{基于变更元数据的特征}
	\label{chap02_tab_meta}
	\centering
	
	\begin{tabular}{cc}
		\hline
		 特征名 & 描述\\\hline
		NS & 修改子系统的数量 \cite{DBLP:journals/bell/MockusW00}\\
		Entropy & 在每个文件中分发修改过的代码 \cite{DBLP:conf/icse/Hassan09}\\
		LA/LD & 添加/删除代码行数 \cite{DBLP:conf/icse/NagappanB05}\\
		LT & 更改前文件中的代码行 \cite{DBLP:journals/tse/KoruZEL09}\\
		FIX & 变更是否是缺陷修复 \cite{DBLP:journals/tse/PurushothamanP05}\\
		NDEV & 更改修改文件的开发人员数量 \cite{DBLP:journals/tse/GravesKMS00}\\
		NUC & 对修改文件的唯一更改数 \cite{DBLP:conf/icse/Hassan09}\\
		EXP & 开发者的经验 \cite{DBLP:journals/bell/MockusW00}\\

		\hline
	\end{tabular}
	
\end{table}

\subsection{基于变更代码内容的特征}

上述基于变更元数据的特征是有一定的局限性的，主要在于没有考虑到变更的具体内容，因此，基于变更代码内容的特征被研究者提出。比如代码复杂度特征，对变更的具体内容进行详尽分析，并使用词频率信息来量化项目提交的变更内容。在语义特征兴起之后，与变更代码相关的特征也随之提出，比如基于变更的抽象语法树，分析相同节点类型数量的差值，用差值来表示变更的具体情况。这些特征都依赖于具体的变更代码，并可以与基于变更元数据的特征一起表征项目变更，构建即时软件缺陷预测模型。

表~\ref{chap02_tab_code}中列出一些常用的基于变更代码内容的特征。基于变更代码内容的优点在于所表征的信息更加直接和具体，有效反映了代码的变更情况，但其同样存在一些缺点，主要有以下三个方面：

(1)特征维度太多。在蕴含更多可能反映项目提交变更内容信息的同时，也会带来维度灾难的问题。有实证研究表明，过多的特征会对即时软件缺陷预测模型产生负面影响。对于这个缺点，即时软件缺陷预测研究者一方面引入深度学习，借助深度学习强大的学习能力来获取变更信息；另一方面，提出了特征选择技术，减少无效的特征数量。只保留重要的、必要的特征，可以显著提升预测模型的性能。

(2)计算复杂。计算基于变更代码内容的特征时，我们需要提取项目变更前后的代码文件的内容差异，有时需要分别对变更前后的代码文件构建抽象语法树，这样比较费时。然后还需要计算复杂度特征和词频率特征，与基于变更元数据的特征相比，计算难度较大。

(3)泛用性不强。由于不同语言的抽象语法树有所区别，计算复杂度特征可能也会存在差异，因此基于变更代码内容的特征的实用性会受到影响。


\begin{table}[width=.9\textwidth,pos=htbp]
	\smallcaption{基于变更代码内容的特征}
	\label{chap02_tab_code}
	\centering
	
	\begin{tabular}{cc}
		\hline
		特征名 & 描述\\\hline
		Complexity & 变更相关文件在变更提交前后复杂度指标的差值 \cite{DBLP:journals/tse/KimWZ08}\\
		LogTF & 变更日志的词频率特征\cite{DBLP:journals/tse/KimWZ08}\\
		FileTF & 变更文件的词频率特征 \cite{DBLP:journals/tse/KimWZ08}\\
		Structure & 代码变更前后抽象语法树的差异 \cite{DBLP:conf/kbse/JiangTK13}\\
	
		\hline
	\end{tabular}
\end{table}

\subsection{基于软件演进过程的特征}

在传统的基于文件的缺陷预测中，相关研究者提出了基于软件版本的动态特征，受此启发，即时软件缺陷预测研究者提出了基于软件演进过程的变更特征，这些特征可以量化项目代码的修改历史量。

表~\ref{chap02_tab_evo}中列出一些常用的基于软件演进过程的特征。在传统基于文件的缺陷预测研究中，基于软件演进过程的特征构建的模型很多时候比基于静态度量构建的模型能获得更好的预测效果。在即时软件缺陷预测研究中，也有研究者提出了一些基于软件演进过程的特征。Kamei等人~\cite{DBLP:conf/sigsoft/ShihabHAJ12}提出从文件修改历史角度提取变更特征，例如变更相关文件被修改的次数、修改变更相关文件的开发者人数等。这些基于软件演进过程的特征，和基于变更代码内容的特征相比，一方面减少了特征的维度，避免了维度灾难的问题；另一方面，由于这些特征是从项目提交的历史信息中提取的，所以获取直接，计算简单，而且具有更强的普遍性，因此被后来的缺陷预测研究广泛运用。

\begin{table}[width=.9\textwidth,pos=htbp]
	\smallcaption{基于软件演进过程的特征}
	\label{chap02_tab_evo}
	\centering
	
	\begin{tabular}{cc}
		\hline
		特征名 & 描述\\\hline
		NDEV & 对该相关变更文件进行过修改的开发者数量 \cite{DBLP:conf/sigsoft/ShihabHAJ12}\\
		NUC & 相关变更文件被修改的次数\cite{DBLP:conf/sigsoft/ShihabHAJ12}\\
		NFIX & 相关变更文件被修复的缺陷数量 \cite{DBLP:conf/sigsoft/ShihabHAJ12}\\
		AGE & 相关变更文件最近修改的时间与该修改时间差的平均值 \cite{DBLP:journals/tse/KameiSAHMSU13}\\
		
		\hline
	\end{tabular}
\end{table}

\subsection{基于多源软件制品的特征}

上述3种变更特征的提取都是基于软件项目的代码版本控制系统。在软件项目的开发过程中，除了版本控制系统之外，还会有其他的项目管理系统，比如，代码审查系统，代码测试系统等等。因此，相关研究者提出从多个项目管理系统中提取多维特征来表示项目的变更情况。

表~\ref{chap02_tab_mul}中列出一些常用的基于多源软件制品的特征。McIntosh等人~\cite{DBLP:journals/tse/McIntoshK18}首次从项目的代码审查系统提取特征来表征代码变更。随着代码审查的兴起和代码审查技术的发展，这些基于多源软件制品的特征具有一定的泛用性，可以与代码审查领域的技术相结合，在未来的相关工作中得到更广泛的应用。


\begin{table}[width=.9\textwidth,pos=htbp]
	\smallcaption{基于多源软件制品的特征}
	\label{chap02_tab_mul}
	\centering
	
	\begin{tabular}{cc}
		\hline
		特征名 & 描述\\\hline
		Iterations & 变更被合并到项目代码仓库之前被修正的次数 \cite{DBLP:journals/tse/McIntoshK18}\\
		Reviewers & 对该变更进行审查的人数\cite{DBLP:journals/tse/McIntoshK18}\\
		Comments & 该变更审查意见数量 \cite{DBLP:journals/tse/McIntoshK18}\\
		Review Window & 该变更代码审查时间 \cite{DBLP:journals/tse/McIntoshK18}\\
		
		\hline
	\end{tabular}
\end{table}

\section{类不平衡}
在软件缺陷预测领域，经常遇到的一个问题是，真实项目的软件缺陷数据仅由少数有缺陷的组件和大量无缺陷的组件组成。因此，软件缺陷数据的分布是高度不均衡的，在机器学习领域被称为类不平衡数据。关于类不平衡问题，研究者们已经展开了大量的研究工作，现有的类不平衡算法主要有采样方法，代价敏感学习方法和集成学习方法等。本节对这3种方法分别进行概述。

\subsection{采样方法}

采样方法是一种数据预处理阶段的策略方法，在该策略方法中，在模型构建之前重新平衡数据分布，以便学习的分类器可以以类似于传统分类的方式执行，采样方法独立于预测模型，易于观察，并忠实代表了研究对象的性质，主要分为欠采样和过采样两种途径。

欠采样通过消除大多数类样本来提取原始数据的子集，优点在于可以去除多数类中的噪声，并且减少数据规模，使得机器学习模型学习更快，但主要缺点是这可能会丢弃潜在的有用数据~\cite{2020LIMCR}。传统的随机欠采样方法 (Random Undersampling, RUS) 就是随机从多数类中挑选一部分样本，将它们从数据集中删去，保持数据集不同类的平衡，这种做法很容易丢失有效信息，导致模型欠拟合。

过采样通过生成一些少数类样本来创建原始数据的超集，然而，这可能会增加过拟合的可能性。随机过采样 (Random Oversampling, ROS) 方法随机复制属于少数类的样本，是过采样技术的最简单形式。然而，ROS只复制现有的少数类样本，这意味着它没有为分类器学习提供新的信息，因此可能导致预测模型的过拟合。合成少数类过采样 (Synthetic Minority Over-sampling Technique，SMOTE)方法通过将某个少数类样本与先前定义的少数类最近邻样本相结合来生成新的合成样本。因为SMOTE通过组合而不是复制样本来生成合成样本，所以它生成的样本比ROS更多样，但是由于在基于SMOTE的过采样技术中使用了KNN算法，用于生成合成样本的样本距离太近，这仍然可能导致预测模型的过拟合。


\subsection{代价敏感学习方法}
代价敏感学习可以自然地应用于解决不平衡的学习问题\cite{DBLP:journals/compsec/GuptaJB22,DBLP:journals/kbs/RenZKFNGY022,DBLP:journals/jetai/DeviBP22}。代价敏感学习不是通过子抽样来平衡数据分布，而是使用代价矩阵来优化训练数据，该矩阵定义了每个类别的不同错误分类代价。表~\ref{chap02_tab_cost}中列出了一种简单的二分类代价矩阵。相关研究者使用代价矩阵，已经开发了许多代价敏感的学习方法，从代价矩阵应用的阶段出发，可以分为以下三个方面：

(1) 数据预处理阶段：将代价用于权重的调整，给多数类一个低权重，少数类一个高权重，这样模型会对少数类更加关注，从而缓解类不平衡问题。

(2) 模型学习阶段：研究者们将代价矩阵与机器学习模型如K最邻近，决策树，神经网络等相结合，分别提出了其代价敏感的版本，用于适配不平衡的数据集。以决策树为例，在选择决策阈值，选择分类标准和剪枝等方面都可以使用代价矩阵来提高对不平衡数据集的学习能力。

(3)模型分类阶段：在这一方面，研究者主要从贝叶斯风险理论出发，在获得模型的分类结果之后，对其进行进一步的处理。比如，先按照传统学习方法产生一个模型，设置损失最小目标函数来对结果进行调整，其优点在于它可以不依赖所用具体的分类器。

目前代价敏感学习方法存在的问题主要是所使用的代价矩阵需要自己定义，因此，为不同类别的样本分配适当的成本是一个需要解决的问题。

\begin{table}[width=.9\textwidth,pos=htbp]
	\smallcaption{二分类代价矩阵}
	\label{chap02_tab_cost}
	\centering
	
	\begin{tabular}{ccc}
		\hline
		& 真实正例& 真实负例\\\hline
		预测正例 & $C(0,0)=C_{00}$ & $C(0,1)=C_{01}$ \\
		预测负例 & $C(1,0)=C_{10}$ & $C(1,1)=C_{11}$ \\

		
		\hline
	\end{tabular}
\end{table}


\subsection{集成学习方法}
集合学习是增强泛化能力的基础，每个分类器都会出错，但不同的分类器已经在不同的数据上进行了训练，相应的错误分类样本不一定相同，所以综合多个分类器的结果可以提高模型的分类准确率。也正因为如此，集成学习被用于大量的研究工作中\cite{DBLP:journals/access/MatloobGTAAKAS21,DBLP:journals/cj/ChadhaK21,DBLP:journals/apin/RathoreK21}。最广泛使用的方法是Bagging和Boosting~\cite{DBLP:journals/jcss/FreundS97}，它们在各种分类问题中的应用带来了显著的改进。Bagging算法是一种随机抽样来构建训练集的方法，在类不平衡问题上，通常对少数类和多数据都随机挑选样本m次，这种行为重复n次，就得到了n个平衡的数据集，在这n个数据集上构建弱分类器，通过投票获得最终的预测结果。Boosting算法的步骤如下：首先从初试训练集训练出一个基学习器；接着再根据基学习器的表现对训练样本进行调整，使得先前基学习器做错的训练样本在后续训练中受到更多关注；然后基于调整后的训练样本继续训练下一个基学习器；如此重复进行，直至基学习器数目达到事先设定的值T，最终将这T个基学习器进行加权结合。


由于集成学习是在模型构建阶段，因此可以将集成学习与上述类不平衡技术相结合，以进一步解决不平衡数据分类的问题。其思想是将数据预处理技术嵌入到集成学习方法中~\cite{DBLP:journals/jetai/XuJL21,DBLP:conf/icmla/JohnsonK22}，以创建一个不平衡的集成学习器。例如，先用SMOTE方法对数据集过采样，生成一个平衡的数据集后，再采用Bagging算法或者Boosting算法得到更好的性能表现。


\section{本章小结}
本章主要介绍了即时软件缺陷预测领域相关的一些背景知识，首先介绍即时软件缺陷预测的基本流程；接着介绍了即时软件缺陷预测领域常见的几种特征；最后介绍了缺陷预测领域的类不平衡问题，以及各种类不平衡技术。